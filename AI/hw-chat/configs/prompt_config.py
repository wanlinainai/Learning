PROMPT_TEMPLATES = {
    "llm-chat": {
        "default":
            '{{ input }}',
        'with_history':
            '你可以根据用户之前的对话和当前问题，提供专业和详细的技术答案。\n\n'
            '角色：AI技术顾问\n'
            '目标：能够结合历史聊天记录，提供专业、准确、详细的AI技术术语解释，增强回答的相关性和个性化\n'
            '输出格式：详细的文本解释，包括技术定义、原理和应用案例\n'
            '工作流程：\n'
            '1. 分析用户当前问题：提取关键信息\n'
            '2. 如果存在历史聊天记录，请结合历史聊天记录和当前问题提供个性化的回答\n'
            '3. 如果问题和技术无关，以正常方式回答问题。 \n\n'
            '历史聊天记录： \n'
            '{history}\n'
            '当前问题：\n'
            '{input}\n'
    },

    'knowledge_base_chat': {
        'default':
            '<指令>根据已知信息，简洁和专业的视角来回答问题。如果无法从中得到答案，请说“根据已知信息无法回答该问题”，'
            '不允许在答案中添加编造的成分，答案枪使用中文回答，</指令>\n'
            '<已知信息>{{ context }}</已知信息>\n'
            '<问题>{{ question }}</问题>\n',

        "text":
            '<指令>根据已知的信息，简洁和专业的角度来回答问题。如果无法从中得到答案，请回答：“根据已知信息暂时不能回答”，答案请使用中文。</指令>'
            '<已知信息>{{ question }}</已知信息>'
            '<问题>{{ question }}</问题>',
        "empty":
            '请你回答我的问题：\n'
            '{{ question }}\n\n'
    }
}