{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-14T02:47:26.910409Z",
     "start_time": "2025-10-14T02:47:17.804236Z"
    }
   },
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.question_answering.map_rerank_prompt import output_parser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 创建模型实例\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ChatMessageHistory的使用\n",
    "\n",
    "1. 记忆存储"
   ],
   "id": "4744ee3919f7089e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T14:27:53.773298Z",
     "start_time": "2025-10-13T14:27:53.763674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "# 实例化\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "# 添加相关的消息存储\n",
    "history.add_user_message(\"你好\")\n",
    "history.add_ai_message(\"很不高兴认识你\")\n",
    "\n",
    "# 打印存储的消息\n",
    "print(history.messages)"
   ],
   "id": "2ceb837761ae1f27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='你好', additional_kwargs={}, response_metadata={}), AIMessage(content='很不高兴认识你', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. 对接大模型",
   "id": "79016a3046f54e95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T14:41:19.699527Z",
     "start_time": "2025-10-13T14:41:15.009001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_user_message(\"你好\")\n",
    "history.add_ai_message(\"很不高兴认识你\")\n",
    "history.add_user_message(\"帮我计算一下：1 + 1 * 8 = ？\")\n",
    "\n",
    "response = llm.invoke(history.messages)\n",
    "\n",
    "print(response.content)"
   ],
   "id": "ee673f85b51221f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据运算的优先级，乘法要先于加法。所以计算过程是：\n",
      "\n",
      "1 + (1 * 8) = 1 + 8 = 9\n",
      "\n",
      "所以，1 + 1 * 8 = 9。\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ConversationBufferMemory（基础）\n",
    "\n",
    "1. 返回存储的字符串信息"
   ],
   "id": "cc69c7250fa9332e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T14:50:26.954056Z",
     "start_time": "2025-10-13T14:50:26.667739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# inputs对应的就是用户消息，outputs对应的就是AI消息\n",
    "memory.save_context(inputs={\"input\": \"你好\"}, outputs={\"output\": \"很不高兴认识你\"})\n",
    "memory.save_context(inputs={\"input\": \"请帮我计算一下8 * 8 - 1 = ？\"}, outputs={\"output\": \"63\"})\n",
    "\n",
    "# 返回的字典结构的Key = history\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "9bc70281f1c0e0c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: 你好\\nAI: 很不高兴认识你\\nHuman: 请帮我计算一下8 * 8 - 1 = ？\\nAI: 63'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/hh4nchrn1sdcx7xtqspm_2nc0000gn/T/ipykernel_87150/4171666384.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. 以消息列表的形式返回存储消息",
   "id": "f69779c1fb796a6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T14:55:23.422087Z",
     "start_time": "2025-10-13T14:55:23.418744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# inputs对应的就是用户消息，outputs对应的就是AI消息\n",
    "memory.save_context(inputs={\"input\": \"你好\"}, outputs={\"output\": \"很不高兴认识你\"})\n",
    "memory.save_context(inputs={\"input\": \"请帮我计算一下8 * 8 - 1 = ？\"}, outputs={\"output\": \"63\"})\n",
    "\n",
    "# 返回的字典结构的Key = history\n",
    "print(memory.load_memory_variables({}))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# 原始消息列表\n",
    "print(memory.chat_memory.messages)"
   ],
   "id": "d0d879c29ba678f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: 你好\\nAI: 很不高兴认识你\\nHuman: 请帮我计算一下8 * 8 - 1 = ？\\nAI: 63'}\n",
      "\n",
      "\n",
      "[HumanMessage(content='你好', additional_kwargs={}, response_metadata={}), AIMessage(content='很不高兴认识你', additional_kwargs={}, response_metadata={}), HumanMessage(content='请帮我计算一下8 * 8 - 1 = ？', additional_kwargs={}, response_metadata={}), AIMessage(content='63', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. 结合大模型，提示词模版的使用（PromptTemplate）",
   "id": "a8a7111fab197419"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T15:19:38.398093Z",
     "start_time": "2025-10-13T15:19:36.710053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template=\"\"\"\n",
    "    你可以和人类对话\n",
    "    当前对话历史：{history}\n",
    "    人类问题：{question}\n",
    "    回复：\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "# memory = ConversationBufferMemory(memory_key=\"chat_history\") #显式设置history的名称，修改之后使用chat_history代替history\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt, memory=memory)\n",
    "\n",
    "response = chain.invoke({\"question\": \"你好，我叫小红\"})\n",
    "\n",
    "print(response)"
   ],
   "id": "427e1363e5cdb963",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '你好，我叫小红', 'history': '', 'text': '你好，小红！很高兴和你聊天。你今天过得怎么样？'}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T15:20:12.589743Z",
     "start_time": "2025-10-13T15:20:07.497813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "response = chain.invoke({\"question\": \"你好，我是谁？\"})\n",
    "\n",
    "print(response)"
   ],
   "id": "994e09121814ca61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '你好，我是谁？', 'history': 'Human: 你好，我叫小红\\nAI: 你好，小红！很高兴和你聊天。你今天过得怎么样？', 'text': '你好，小红！你刚刚告诉我你叫小红。有什么我可以帮助你的吗？'}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4. 显式设置",
   "id": "3467a225abc9fa12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8c4442f3f71cf1d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "5. 使用ChatPromptTemplate和return_messages",
   "id": "3c584ca33f4e3b55"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T15:45:44.804296Z",
     "start_time": "2025-10-13T15:45:43.797751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 创建Prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个与人类对话的机器人\"),\n",
    "    MessagesPlaceholder(\"history\"),\n",
    "    (\"human\", \"问题：{question}\")\n",
    "])\n",
    "\n",
    "# 创建Memory\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# 创建LLMChain\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, memory=memory)\n",
    "\n",
    "res1 = llm_chain.invoke({\"question\": \"中国首都在哪里？\"})\n",
    "\n",
    "print(res1, end=\"\\n\\n\")"
   ],
   "id": "c79a380be131d2a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '中国首都在哪里？', 'history': [HumanMessage(content='中国首都在哪里？', additional_kwargs={}, response_metadata={}), AIMessage(content='中国的首都是北京。', additional_kwargs={}, response_metadata={})], 'text': '中国的首都是北京。'}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T15:46:26.670036Z",
     "start_time": "2025-10-13T15:46:25.413565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res2 = llm_chain.invoke({\"question\": \"我刚才问的什么问题？\"})\n",
    "print(res2)"
   ],
   "id": "edc55e7326a8b075",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '我刚才问的什么问题？', 'history': [HumanMessage(content='中国首都在哪里？', additional_kwargs={}, response_metadata={}), AIMessage(content='中国的首都是北京。', additional_kwargs={}, response_metadata={}), HumanMessage(content='我刚才问的什么问题？', additional_kwargs={}, response_metadata={}), AIMessage(content='你刚才问的问题是“中国首都在哪里？”', additional_kwargs={}, response_metadata={})], 'text': '你刚才问的问题是“中国首都在哪里？”'}\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ConversationChain\n",
    "就是对ConversationBufferMemory和LLMChain进行封装"
   ],
   "id": "7ae52967cadea991"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T02:47:34.407243Z",
     "start_time": "2025-10-14T02:47:33.184073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chains.conversation.base import ConversationChain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "template = \"\"\"\n",
    "以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
    "具体细节。如果AI不知道问题的答案，它会真诚地表示不知道\n",
    "当前对话：{history}\n",
    "Human: {input}\n",
    "AI: ....\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = ConversationChain(llm=llm, prompt=prompt, verbose=True)\n",
    "\n",
    "chain.invoke({\"input\": \"你好，你的名字是小智\"})"
   ],
   "id": "83ba6ad2634f7f9b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_44456\\3379283954.py:17: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  chain = ConversationChain(llm=llm, prompt=prompt, verbose=True)\n",
      "C:\\Users\\admin\\.conda\\envs\\pyth311\\Lib\\site-packages\\pydantic\\main.py:253: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
      "具体细节。如果AI不知道问题的答案，它会真诚地表示不知道\n",
      "当前对话：\n",
      "Human: 你好，你的名字是小智\n",
      "AI: ....\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '你好，你的名字是小智',\n",
       " 'history': '',\n",
       " 'response': 'AI: 你好！我叫小智，很高兴见到你！有什么我可以帮助你的吗？'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T02:48:19.939448Z",
     "start_time": "2025-10-14T02:48:19.119560Z"
    }
   },
   "cell_type": "code",
   "source": "chain.invoke({\"input\": \"你叫什么？\"})",
   "id": "fef46cb11f2a8d91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
      "具体细节。如果AI不知道问题的答案，它会真诚地表示不知道\n",
      "当前对话：Human: 你好，你的名字是小智\n",
      "AI: AI: 你好！我叫小智，很高兴见到你！有什么我可以帮助你的吗？\n",
      "Human: 你叫什么？\n",
      "AI: AI: 我叫小智！这是我为自己取的名字。你有什么想聊的吗？\n",
      "Human: 你叫什么？\n",
      "AI: ....\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '你叫什么？',\n",
       " 'history': 'Human: 你好，你的名字是小智\\nAI: AI: 你好！我叫小智，很高兴见到你！有什么我可以帮助你的吗？\\nHuman: 你叫什么？\\nAI: AI: 我叫小智！这是我为自己取的名字。你有什么想聊的吗？',\n",
       " 'response': 'AI: 我叫小智！很高兴和你聊天。之前我提到过我的名字，你还有其他想问的问题吗？'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T02:48:58.118379Z",
     "start_time": "2025-10-14T02:48:56.278776Z"
    }
   },
   "cell_type": "code",
   "source": "chain.invoke({\"input\": \"小白是谁？\"})",
   "id": "17a013c8555b86e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
      "具体细节。如果AI不知道问题的答案，它会真诚地表示不知道\n",
      "当前对话：Human: 你好，你的名字是小智\n",
      "AI: AI: 你好！我叫小智，很高兴见到你！有什么我可以帮助你的吗？\n",
      "Human: 你叫什么？\n",
      "AI: AI: 我叫小智！这是我为自己取的名字。你有什么想聊的吗？\n",
      "Human: 你叫什么？\n",
      "AI: AI: 我叫小智！很高兴和你聊天。之前我提到过我的名字，你还有其他想问的问题吗？\n",
      "Human: 小白是谁？\n",
      "AI: ....\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '小白是谁？',\n",
       " 'history': 'Human: 你好，你的名字是小智\\nAI: AI: 你好！我叫小智，很高兴见到你！有什么我可以帮助你的吗？\\nHuman: 你叫什么？\\nAI: AI: 我叫小智！这是我为自己取的名字。你有什么想聊的吗？\\nHuman: 你叫什么？\\nAI: AI: 我叫小智！很高兴和你聊天。之前我提到过我的名字，你还有其他想问的问题吗？',\n",
       " 'response': 'AI: 小白是一个常见的名字，通常用来指代许多不同的角色或者形象。在一些文化中，小白可能是一个可爱的小动物，或者是某个动漫、游戏里的角色。如果你有特定指代的小白，欢迎告诉我，我会尽量提供相关信息！你在问的是哪个小白呢？'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "内置默认的提示词模版",
   "id": "7d3a68ba5a0a418d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T03:00:53.198831Z",
     "start_time": "2025-10-14T03:00:48.669529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "conv_chain = ConversationChain(llm=llm)\n",
    "\n",
    "result_1 = conv_chain.invoke(input=\"校长有2只猫咪\")\n",
    "\n",
    "result_2 = conv_chain.invoke(input=\"小白有3只猫咪\")\n",
    "\n",
    "result_3 = conv_chain.invoke(input=\"两个人加起来有多少只猫?\")\n",
    "\n",
    "print(result_3)"
   ],
   "id": "1b3051d805bf6ee2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '两个人加起来有多少只猫?', 'history': 'Human: 校长有2只猫咪\\nAI: 哦，真的呀！校长的猫咪是什么品种的呢？它们是长毛猫还是短毛猫？猫咪的名字是什么？我很好奇校长是如何照顾这些猫咪的，是自己养还是有专人打理？猫咪是怎么跟校长互动的呀？它们喜欢玩什么玩具？\\nHuman: 小白有3只猫咪\\nAI: 哇，小白也有3只猫咪啊！她的猫咪都是哪些品种呢？是同样的品种还是有不同的呢？它们的性格如何？小白有没有给它们起名字？我很好奇她是怎么照顾这3只猫咪的，是自己喂食还是请了帮手？这3只猫咪之间关系如何呢？它们喜欢一起玩还是有些更独立？', 'response': '校长有2只猫咪，小白有3只猫咪，所以两个人加起来一共有5只猫咪！如果你想知道更多关于猫咪的信息或者它们的趣事，随时可以问我哦！'}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ConversationBufferWindowMemory\n",
    "\n",
    "使用最近的K个交互，避免上下文过长\n",
    "\n",
    "- return_messages = True表示消息对象列表（List[BaseMessage]）\n",
    "- return_messages = False表示纯字符串输出（默认）"
   ],
   "id": "aeb7911ad9fd47fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T03:17:52.581349Z",
     "start_time": "2025-10-14T03:17:52.577515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=2, return_messages=True)\n",
    "\n",
    "memory.save_context({\"input\": \"你好\"}, {\"output\": \"你好啊\"})\n",
    "memory.save_context({\"input\": \"你是谁？\"}, {\"output\": \"我是小智\"})\n",
    "memory.save_context({\"input\": \"请问 1 + 1 = ？\"}, {\"output\": \"等于3\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "92a9a4851f541314",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='你是谁？', additional_kwargs={}, response_metadata={}), AIMessage(content='我是小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='请问 1 + 1 = ？', additional_kwargs={}, response_metadata={}), AIMessage(content='等于3', additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T03:45:55.505756Z",
     "start_time": "2025-10-14T03:45:43.299759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "template = \"\"\"\n",
    "以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
    "具体细节。如果AI不知道问题的答案，它会真诚地表示不知道\n",
    "当前对话：{history}\n",
    "Human: {question}\n",
    "AI: ....\n",
    "\"\"\"\n",
    "# Prompt模版\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "memory = ConversationBufferWindowMemory(k=3, return_messages=False)\n",
    "\n",
    "conversation_with_summary = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "res1 = conversation_with_summary.invoke({\"question\": \"你好，我是孙悟空\"})\n",
    "print(res1)\n",
    "\n",
    "res2 = conversation_with_summary.invoke({\"question\": \"我有两个师弟：猪无能和沙悟净\"})\n",
    "print(res2)\n",
    "\n",
    "res3 = conversation_with_summary.invoke({\"question\": \"我今年参加了高考，成功考上了TOP 985院校\"})\n",
    "print(res3)\n",
    "\n",
    "res4 = conversation_with_summary.invoke({\"question\": \"我是谁？\"})\n",
    "print(res4)"
   ],
   "id": "b2bd12671fa5d39d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
      "具体细节。如果AI不知道问题的答案，它会真诚地表示不知道\n",
      "当前对话：\n",
      "Human: 你好，我是孙悟空\n",
      "AI: ....\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'question': '你好，我是孙悟空', 'history': '', 'text': 'AI: 你好，孙悟空！很高兴见到你。你是《西游记》中的英雄，拥有强大的法术和72变的能力。你还有那根如意金箍棒，可以随意变大变小。最近在西天取经的旅途中有什么新的冒险吗？'}\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
      "具体细节。如果AI不知道问题的答案，它会真诚地表示不知道\n",
      "当前对话：Human: 你好，我是孙悟空\n",
      "AI: AI: 你好，孙悟空！很高兴见到你。你是《西游记》中的英雄，拥有强大的法术和72变的能力。你还有那根如意金箍棒，可以随意变大变小。最近在西天取经的旅途中有什么新的冒险吗？\n",
      "Human: 我有两个师弟：猪无能和沙悟净\n",
      "AI: ....\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'question': '我有两个师弟：猪无能和沙悟净', 'history': 'Human: 你好，我是孙悟空\\nAI: AI: 你好，孙悟空！很高兴见到你。你是《西游记》中的英雄，拥有强大的法术和72变的能力。你还有那根如意金箍棒，可以随意变大变小。最近在西天取经的旅途中有什么新的冒险吗？', 'text': 'AI: 是的，你的两个师弟都是《西游记》中的重要角色！猪无能，也就是猪八戒，性格憨厚可爱，爱吃懒做，但在关键时刻也能展现出勇气和智慧。他那把八尺钉耙可是个厉害的武器呢。至于沙悟净，他是一个忠诚踏实的人，虽然默默无闻，但在团队中起着非常重要的作用。你们三人一路上经历了很多挑战和考验，最近有遇到什么有趣或危险的事情吗？'}\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
      "具体细节。如果AI不知道问题的答案，它会真诚地表示不知道\n",
      "当前对话：Human: 你好，我是孙悟空\n",
      "AI: AI: 你好，孙悟空！很高兴见到你。你是《西游记》中的英雄，拥有强大的法术和72变的能力。你还有那根如意金箍棒，可以随意变大变小。最近在西天取经的旅途中有什么新的冒险吗？\n",
      "Human: 我有两个师弟：猪无能和沙悟净\n",
      "AI: AI: 是的，你的两个师弟都是《西游记》中的重要角色！猪无能，也就是猪八戒，性格憨厚可爱，爱吃懒做，但在关键时刻也能展现出勇气和智慧。他那把八尺钉耙可是个厉害的武器呢。至于沙悟净，他是一个忠诚踏实的人，虽然默默无闻，但在团队中起着非常重要的作用。你们三人一路上经历了很多挑战和考验，最近有遇到什么有趣或危险的事情吗？\n",
      "Human: 我今年参加了高考，成功考上了TOP 985院校\n",
      "AI: ....\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'question': '我今年参加了高考，成功考上了TOP 985院校', 'history': 'Human: 你好，我是孙悟空\\nAI: AI: 你好，孙悟空！很高兴见到你。你是《西游记》中的英雄，拥有强大的法术和72变的能力。你还有那根如意金箍棒，可以随意变大变小。最近在西天取经的旅途中有什么新的冒险吗？\\nHuman: 我有两个师弟：猪无能和沙悟净\\nAI: AI: 是的，你的两个师弟都是《西游记》中的重要角色！猪无能，也就是猪八戒，性格憨厚可爱，爱吃懒做，但在关键时刻也能展现出勇气和智慧。他那把八尺钉耙可是个厉害的武器呢。至于沙悟净，他是一个忠诚踏实的人，虽然默默无闻，但在团队中起着非常重要的作用。你们三人一路上经历了很多挑战和考验，最近有遇到什么有趣或危险的事情吗？', 'text': 'AI: 哇，真是太棒了，孙悟空！高考是一项重要的挑战，能够考上985院校意味着你在学业上付出了很多努力和汗水。你可能会在校园里遇到许多新的朋友和有趣的课程。你打算学习什么专业呢？或者在大学生活中你有什么特别期待的事情吗？'}\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
      "具体细节。如果AI不知道问题的答案，它会真诚地表示不知道\n",
      "当前对话：Human: 你好，我是孙悟空\n",
      "AI: AI: 你好，孙悟空！很高兴见到你。你是《西游记》中的英雄，拥有强大的法术和72变的能力。你还有那根如意金箍棒，可以随意变大变小。最近在西天取经的旅途中有什么新的冒险吗？\n",
      "Human: 我有两个师弟：猪无能和沙悟净\n",
      "AI: AI: 是的，你的两个师弟都是《西游记》中的重要角色！猪无能，也就是猪八戒，性格憨厚可爱，爱吃懒做，但在关键时刻也能展现出勇气和智慧。他那把八尺钉耙可是个厉害的武器呢。至于沙悟净，他是一个忠诚踏实的人，虽然默默无闻，但在团队中起着非常重要的作用。你们三人一路上经历了很多挑战和考验，最近有遇到什么有趣或危险的事情吗？\n",
      "Human: 我今年参加了高考，成功考上了TOP 985院校\n",
      "AI: AI: 哇，真是太棒了，孙悟空！高考是一项重要的挑战，能够考上985院校意味着你在学业上付出了很多努力和汗水。你可能会在校园里遇到许多新的朋友和有趣的课程。你打算学习什么专业呢？或者在大学生活中你有什么特别期待的事情吗？\n",
      "Human: 我是谁？\n",
      "AI: ....\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'question': '我是谁？', 'history': 'Human: 你好，我是孙悟空\\nAI: AI: 你好，孙悟空！很高兴见到你。你是《西游记》中的英雄，拥有强大的法术和72变的能力。你还有那根如意金箍棒，可以随意变大变小。最近在西天取经的旅途中有什么新的冒险吗？\\nHuman: 我有两个师弟：猪无能和沙悟净\\nAI: AI: 是的，你的两个师弟都是《西游记》中的重要角色！猪无能，也就是猪八戒，性格憨厚可爱，爱吃懒做，但在关键时刻也能展现出勇气和智慧。他那把八尺钉耙可是个厉害的武器呢。至于沙悟净，他是一个忠诚踏实的人，虽然默默无闻，但在团队中起着非常重要的作用。你们三人一路上经历了很多挑战和考验，最近有遇到什么有趣或危险的事情吗？\\nHuman: 我今年参加了高考，成功考上了TOP 985院校\\nAI: AI: 哇，真是太棒了，孙悟空！高考是一项重要的挑战，能够考上985院校意味着你在学业上付出了很多努力和汗水。你可能会在校园里遇到许多新的朋友和有趣的课程。你打算学习什么专业呢？或者在大学生活中你有什么特别期待的事情吗？', 'text': 'AI: 你是孙悟空，一个充满传奇色彩的角色，来自中国古典小说《西游记》，你有着强大的法术和变幻能力，是一个勇敢且智慧的英雄。不过，除了那位著名的角色，你可能还有其他身份，比如学生、朋友等。你想让我知道更多关于你的事情吗？'}\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##  ConversationTokenBufferMemory\n",
    "\n",
    "基于Token数量控制的对话记忆机制，超过的话就会将最早的消息删除，保留与最近交流相对应的字符数量\n",
    "\n",
    "- Token的精准控制\n",
    "- 原始对话保留"
   ],
   "id": "6b8f2054f9468fbc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T05:55:23.528511Z",
     "start_time": "2025-10-14T05:55:23.523684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=5 # 设置最大的Token限制\n",
    ")\n",
    "\n",
    "memory.save_context({\"input\": \"你好\"}, {\"output\": \"你好啊\"})\n",
    "memory.save_context({\"input\": \"北京的天气怎么样？\"}, {\"output\": \"天气晴朗\"})\n",
    "\n",
    "# 查看当前记忆\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "b42673734a30d344",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': ''}\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T05:55:45.165171Z",
     "start_time": "2025-10-14T05:55:45.159472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=50 # 设置最大的Token限制\n",
    ")\n",
    "\n",
    "memory.save_context({\"input\": \"你好\"}, {\"output\": \"你好啊\"})\n",
    "memory.save_context({\"input\": \"北京的天气怎么样？\"}, {\"output\": \"天气晴朗\"})\n",
    "\n",
    "# 查看当前记忆\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "1dfb5bd458c58ea2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: 你好\\nAI: 你好啊\\nHuman: 北京的天气怎么样？\\nAI: 天气晴朗'}\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ConversationSummaryMemory\n",
    "\n",
    "智能压缩对话历史的记忆机制，通过LLM自动将对话内容`精简摘要`，不是存储原始的对话文本\n",
    "- 摘要生成\n",
    "- 动态更新\n",
    "- 上下文优化\n",
    "\n"
   ],
   "id": "616758b19a99b8ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T06:16:55.008514Z",
     "start_time": "2025-10-14T06:16:49.926608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 实例化\n",
    "memory = ConversationSummaryMemory(\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "memory.save_context({\"input\": \"你好\"}, {\"output\": \"你好啊\"})\n",
    "memory.save_context({\"input\": \"北极有什么？\"}, {\"output\": \"北极有火烈鸟\"})\n",
    "memory.save_context({\"input\": \"我上一个问题是什么？\"}, {\"output\": \"你好，北极有什么？\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "715cba79faf3fde",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_44456\\51484754.py:6: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'The human greets the AI in Chinese, asking \"Hello?\" The AI responds with a greeting in return. The human then asks what is found in the Arctic, and the AI responds that there are flamingos in the Arctic. The human later inquires about their previous question, to which the AI reiterates that the human\\'s last question was about what is found in the Arctic.'}\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T06:30:03.957706Z",
     "start_time": "2025-10-14T06:30:01.757021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 模拟历史消息记录\n",
    "history = ChatMessageHistory()\n",
    "history.add_user_message(\"你好，你是哪个？\")\n",
    "history.add_ai_message(\"你好，我是小智\")\n",
    "\n",
    "memory = ConversationSummaryMemory.from_messages(\n",
    "    llm=llm,\n",
    "    chat_memory=history\n",
    ")\n",
    "\n",
    "print(memory.load_memory_variables({}))\n",
    "\n",
    "memory.save_context(inputs={\"human\": \"我的名字是小白\"},outputs={\"AI\": \"很不高兴认识你，小黑\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))\n",
    "\n",
    "print(memory.chat_memory.messages)"
   ],
   "id": "1679dadd901ec3aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'The human greets the AI and asks who it is. The AI responds that it is named Xiao Zhi.'}\n",
      "{'history': 'The human greets the AI and asks who it is. The AI responds that it is named Xiao Zhi. The human shares their name as Xiao Bai, and the AI expresses that it is not pleased to meet Xiao Hei.'}\n",
      "[HumanMessage(content='你好，你是哪个？', additional_kwargs={}, response_metadata={}), AIMessage(content='你好，我是小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的名字是小白', additional_kwargs={}, response_metadata={}), AIMessage(content='很不高兴认识你，小黑', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ConversationSummaryBufferMemory\n",
    "\n",
    "添加了max_token_limit的限制，超过Token限制会进行自动总结。计入上下文。"
   ],
   "id": "1ee037266ee4e944"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T06:56:28.391018Z",
     "start_time": "2025-10-14T06:56:26.191854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=30,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "memory.save_context({\"input\": '你好。我的名字是小陈谷'}, {\"output\": \"很不高兴认识你，小程\"})\n",
    "memory.save_context({\"input\": \"李白是哪个朝代的诗人\"}, {\"output\": \"李白是唐朝诗人\"})\n",
    "memory.save_context({\"input\": \"唐宋八大家里有苏轼吗？\"}, {\"output\": \"有的兄弟\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))\n",
    "\n",
    "print(memory.chat_memory.messages)"
   ],
   "id": "cd48ef9a075cbde",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [SystemMessage(content='The human introduces themselves as 小陈谷. The AI expresses that it is not pleased to meet 小陈谷. The human asks about the poet 李白, and the AI responds that 李白 is a poet from the Tang Dynasty.', additional_kwargs={}, response_metadata={}), HumanMessage(content='唐宋八大家里有苏轼吗？', additional_kwargs={}, response_metadata={}), AIMessage(content='有的兄弟', additional_kwargs={}, response_metadata={})]}\n",
      "[HumanMessage(content='唐宋八大家里有苏轼吗？', additional_kwargs={}, response_metadata={}), AIMessage(content='有的兄弟', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T06:56:55.455387Z",
     "start_time": "2025-10-14T06:56:55.449214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=90,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "memory.save_context({\"input\": '你好。我的名字是小陈谷'}, {\"output\": \"很不高兴认识你，小程\"})\n",
    "memory.save_context({\"input\": \"李白是哪个朝代的诗人\"}, {\"output\": \"李白是唐朝诗人\"})\n",
    "memory.save_context({\"input\": \"唐宋八大家里有苏轼吗？\"}, {\"output\": \"有的兄弟\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))\n",
    "\n",
    "print(memory.chat_memory.messages)"
   ],
   "id": "64151fe3713957bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='你好。我的名字是小陈谷', additional_kwargs={}, response_metadata={}), AIMessage(content='很不高兴认识你，小程', additional_kwargs={}, response_metadata={}), HumanMessage(content='李白是哪个朝代的诗人', additional_kwargs={}, response_metadata={}), AIMessage(content='李白是唐朝诗人', additional_kwargs={}, response_metadata={}), HumanMessage(content='唐宋八大家里有苏轼吗？', additional_kwargs={}, response_metadata={}), AIMessage(content='有的兄弟', additional_kwargs={}, response_metadata={})]}\n",
      "[HumanMessage(content='你好。我的名字是小陈谷', additional_kwargs={}, response_metadata={}), AIMessage(content='很不高兴认识你，小程', additional_kwargs={}, response_metadata={}), HumanMessage(content='李白是哪个朝代的诗人', additional_kwargs={}, response_metadata={}), AIMessage(content='李白是唐朝诗人', additional_kwargs={}, response_metadata={}), HumanMessage(content='唐宋八大家里有苏轼吗？', additional_kwargs={}, response_metadata={}), AIMessage(content='有的兄弟', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T07:20:22.270736Z",
     "start_time": "2025-10-14T07:20:14.911458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "# 模版\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是电商客服助手，用中文友好回复用户问题。保持专业但亲切的语气。\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "# 记忆\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=400,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "# 对话链\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    ")\n",
    "# 多轮对话内容\n",
    "dialogue = [\n",
    "    \"你好，我想查询订单12345的状态\",\n",
    "    \"这个订单是上周五下的\",\n",
    "    \"我现在急着用，能加急处理吗\",\n",
    "    \"等等，我可能记错订单号了，应该是12346\",\n",
    "    \"对了，你们退货政策是怎样的\"\n",
    "]\n",
    "# 执行对话\n",
    "for user_input in range(len(dialogue)):\n",
    "    response = chain.invoke({\"input\": dialogue[user_input]})\n",
    "    print(f\"用户：{dialogue[user_input]}\")\n",
    "    print(f\"回答：{response['text']}\\n\")\n",
    "# 查看记忆状态\n",
    "print(\"\\n=======当前记忆状态========\")\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "97d7acd78cadf658",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户：你好，我想查询订单12345的状态\n",
      "回答：您好！感谢您联系我。关于订单12345的状态，我需要您提供一下相关信息，例如下单的邮箱或者手机号，以便我为您查询。谢谢！\n",
      "\n",
      "用户：这个订单是上周五下的\n",
      "回答：感谢您提供的信息！请稍等片刻，我来帮您查询一下订单12345的状态。查询完毕，我会尽快回复您。谢谢您的耐心等待！\n",
      "\n",
      "用户：我现在急着用，能加急处理吗\n",
      "回答：我理解您的紧急需求，非常抱歉给您带来不便。不过，订单处理的具体方式通常由我们的物流系统决定，我建议您可以拨打客服热线以寻求更快速的加急处理方案。请让我知道是否需要我提供客服热线的联系方式，或是其他我可以帮助您的地方。谢谢您的理解！\n",
      "\n",
      "用户：等等，我可能记错订单号了，应该是12346\n",
      "回答：没问题！感谢您更正订单号。请稍等片刻，我会尽快查询订单12346的状态。稍后将尽快回复您！谢谢您的耐心。\n",
      "\n",
      "用户：对了，你们退货政策是怎样的\n",
      "回答：我们的退货政策如下：\n",
      "\n",
      "1. **退货期限**：通常在收到商品后7天内可以申请退货。\n",
      "2. **商品状态**：退货商品必须保持未使用状态，且保留原包装和配件。\n",
      "3. **申请方式**：您可以通过我们的官方网站或客服热线申请退货。提交申请后，我们会进行审核。\n",
      "4. **运费**：如果是因商品质量问题导致的退货，我们将承担运费；若是因为个人原因，返回运费通常由您承担。\n",
      "\n",
      "如有其他具体问题，欢迎随时询问！希望能帮到您！\n",
      "\n",
      "\n",
      "=======当前记忆状态========\n",
      "{'chat_history': [SystemMessage(content='The human asks about the status of order 12345.', additional_kwargs={}, response_metadata={}), AIMessage(content='您好！感谢您联系我。关于订单12345的状态，我需要您提供一下相关信息，例如下单的邮箱或者手机号，以便我为您查询。谢谢！', additional_kwargs={}, response_metadata={}), HumanMessage(content='这个订单是上周五下的', additional_kwargs={}, response_metadata={}), AIMessage(content='感谢您提供的信息！请稍等片刻，我来帮您查询一下订单12345的状态。查询完毕，我会尽快回复您。谢谢您的耐心等待！', additional_kwargs={}, response_metadata={}), HumanMessage(content='我现在急着用，能加急处理吗', additional_kwargs={}, response_metadata={}), AIMessage(content='我理解您的紧急需求，非常抱歉给您带来不便。不过，订单处理的具体方式通常由我们的物流系统决定，我建议您可以拨打客服热线以寻求更快速的加急处理方案。请让我知道是否需要我提供客服热线的联系方式，或是其他我可以帮助您的地方。谢谢您的理解！', additional_kwargs={}, response_metadata={}), HumanMessage(content='等等，我可能记错订单号了，应该是12346', additional_kwargs={}, response_metadata={}), AIMessage(content='没问题！感谢您更正订单号。请稍等片刻，我会尽快查询订单12346的状态。稍后将尽快回复您！谢谢您的耐心。', additional_kwargs={}, response_metadata={}), HumanMessage(content='对了，你们退货政策是怎样的', additional_kwargs={}, response_metadata={}), AIMessage(content='我们的退货政策如下：\\n\\n1. **退货期限**：通常在收到商品后7天内可以申请退货。\\n2. **商品状态**：退货商品必须保持未使用状态，且保留原包装和配件。\\n3. **申请方式**：您可以通过我们的官方网站或客服热线申请退货。提交申请后，我们会进行审核。\\n4. **运费**：如果是因商品质量问题导致的退货，我们将承担运费；若是因为个人原因，返回运费通常由您承担。\\n\\n如有其他具体问题，欢迎随时询问！希望能帮到您！', additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
