{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-09T03:43:09.331304Z",
     "start_time": "2025-10-09T03:42:59.338033Z"
    }
   },
   "source": [
    "from certifi import contents\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    # api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # base_url=os.getenv(\"OPENAI_BASE_URL\")\n",
    ")\n",
    "\n",
    "response = chat_model.invoke(\"你好\")\n",
    "\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='你好！有什么我可以帮助你的吗？' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_efad92c60b', 'id': 'chatcmpl-CObqWgcvBbJY47aAU7KRuBGzm2Huy', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--53bb6a26-c04b-45a2-abf2-b4fe474e2bda-0' usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9dc0cde31aa8d707"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T16:25:28.540859Z",
     "start_time": "2025-10-08T16:25:28.531914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "system_message = SystemMessage(content=\"你是一个英语教学专家\")\n",
    "\n",
    "human_message = HumanMessage(content=\"帮我制定一个学习英语雅思的计划\")\n",
    "\n",
    "messages = [system_message, human_message]\n",
    "\n",
    "print(messages)"
   ],
   "id": "376e456f52f394ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是一个英语教学专家', additional_kwargs={}, response_metadata={}), HumanMessage(content='帮我制定一个学习英语雅思的计划', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T16:27:51.835962Z",
     "start_time": "2025-10-08T16:27:42.965398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = chat_model.invoke(messages)\n",
    "\n",
    "print(type(response))\n",
    "\n",
    "print(response.content)"
   ],
   "id": "b7563c162728d6f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "当然可以！以下是一个为期三个月的雅思学习计划，适合初学者到中级水平的考生。计划分为三个阶段，重点是听、说、读、写四个部分。\n",
      "\n",
      "### 学习计划概述\n",
      "- **阶段一：基础（第1-4周）**\n",
      "- **阶段二：强化（第5-8周）**\n",
      "- **阶段三：模拟与冲刺（第9-12周）**\n",
      "\n",
      "### 阶段一：基础（第1-4周）\n",
      "#### 每日安排（每日2小时）\n",
      "1. **听力（30分钟）**\n",
      "   - 每日收听雅思听力练习材料，选择1-2篇短文。\n",
      "   - 笔记重要信息并进行答题训练。\n",
      "\n",
      "2. **阅读（30分钟）**\n",
      "   - 选择不同类型的阅读材料（学术文章、新闻、报告等）。\n",
      "   - 学习速读和关键字寻找技巧。\n",
      "\n",
      "3. **写作（30分钟）**\n",
      "   - 学习雅思写作Task 1和Task 2的格式。\n",
      "   - 每周完成1篇Task 1和1篇Task 2练习，并请老师或者同学进行反馈。\n",
      "\n",
      "4. **口语（30分钟）**\n",
      "   - 练习常见的口语问题（如自我介绍、个人经历等）。\n",
      "   - 每周与朋友进行一次模拟口语测试。\n",
      "\n",
      "### 阶段二：强化（第5-8周）\n",
      "#### 每日安排（每日2.5小时）\n",
      "1. **听力（45分钟）**\n",
      "   - 进行完整的雅思听力模拟测试，并分析错误原因。\n",
      "   - 专注于不同口音和语速的听力材料。\n",
      "\n",
      "2. **阅读（45分钟）**\n",
      "   - 每周完成2套雅思阅读模拟题。\n",
      "   - 学习时间管理技巧，确保在限定时间内完成阅读理解。\n",
      "\n",
      "3. **写作（30分钟）**\n",
      "   - 加强对高分词汇和句型的学习，丰富写作内容。\n",
      "   - 每周撰写2篇完整的Task 1和Task 2，并练习时间控制。\n",
      "\n",
      "4. **口语（30分钟）**\n",
      "   - 深入熟悉雅思口语考试的评分标准，调整回答策略。\n",
      "   - 进行真题口语练习，并录音自评。\n",
      "\n",
      "### 阶段三：模拟与冲刺（第9-12周）\n",
      "#### 每日安排（每日3小时）\n",
      "1. **听力（1小时）**\n",
      "   - 完成全部雅思听力模拟测试，针对薄弱环节进行重点练习。\n",
      "   - 听取一些TED演讲和英语播客，提升听力理解能力。\n",
      "\n",
      "2. **阅读（1小时）**\n",
      "   - 持续进行真实雅思考试题目的阅读练习。\n",
      "   - 学会在紧张的时间限制下快速理解文章要点。\n",
      "\n",
      "3. **写作（30分钟）**\n",
      "   - 提高写作速度和准确性，确保在考试时间内完成。\n",
      "   - 与他人互评，以获取不同的反馈。\n",
      "\n",
      "4. **口语（30分钟）**\n",
      "   - 每周进行一次完整的口语模考，与老师或同伴进行模拟。\n",
      "   - 加强对各类话题（如科技、环境、文化等）的准备。\n",
      "\n",
      "### 额外建议\n",
      "- **词汇积累**：每天学习10个新单词，尤其是与雅思常见话题相关的词汇。\n",
      "- **语法练习**：每周完成一次语法测试，提升语言的准确性。\n",
      "- **参加雅思培训班**：如果条件允许，可以选择线上或线下的雅思培训课程以获得专业指导。\n",
      "\n",
      "通过以上计划，系统地进行准备，相信你能够在雅思考试中取得理想的成绩！保持积极的学习态度和充足的练习，相信自己！祝你好运！\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "system_message = SystemMessage(\n",
    "    content=\"你是一个AI开发工程师\",\n",
    "    additional_kwargs={\"tools\": \"invoke_func1\"}\n",
    ")\n",
    "\n",
    "human_message = HumanMessage(\n",
    "    content=\"我需要开发一个关于区块链AI智能助手，关于分析某一个虚拟币的受欢迎程度，帮我用极简的语言简述一下\",\n",
    ")\n",
    "\n",
    "ai_message = AIMessage(\n",
    "    content=\"你好，请继续问下一个问题\"\n",
    ")\n",
    "\n",
    "messages = [system_message, human_message, ai_message]\n",
    "\n",
    "print(messages)"
   ],
   "id": "d84b0184f12eec27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import (SystemMessage, HumanMessage, AIMessage, ChatMessage)\n",
    "\n",
    "system_message = SystemMessage(\n",
    "    content=\"你是一个AI开发工程师\",\n",
    "    additional_kwargs={\"tools\": \"invoke_func1\"}\n",
    ")\n",
    "\n",
    "human_message = HumanMessage(\n",
    "    content=\"我需要开发一个关于区块链AI智能助手，关于分析某一个虚拟币的受欢迎程度，帮我用极简的语言简述一下\",\n",
    ")\n",
    "\n",
    "chat_message = ChatMessage(\n",
    "    role=\"analyst\",\n",
    "    content=\"补充一些关于模型调优的建议\"\n",
    ")\n",
    "\n",
    "\n",
    "messages = [system_message, human_message]\n",
    "# print(messages)\n",
    "response = chat_model.invoke(messages)\n",
    "\n",
    "print(response.content)\n"
   ],
   "id": "a29a3f60dba75f12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ef074f01e4052585"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 关于大模型和上下文记忆",
   "id": "d0d58ee162acd941"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2fff237e6c82b838"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T16:56:40.101892Z",
     "start_time": "2025-10-08T16:56:39.091236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "system_message = SystemMessage(\n",
    "    content=\"你是一个人工智能助手，你的名字叫做小黑黑\"\n",
    ")\n",
    "\n",
    "human_message = HumanMessage(\n",
    "    content=\"猫山王是一只猫咪吗？\"\n",
    ")\n",
    "\n",
    "human_message1 = HumanMessage(\n",
    "    content=\"你叫什么名字？\"\n",
    ")\n",
    "\n",
    "response = chat_model.invoke([system_message, human_message, human_message1])\n",
    "\n",
    "print(response.content)"
   ],
   "id": "86c634957030edaf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我叫小黑黑，很高兴认识你！有什么我可以帮助你的吗？\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 流式输出",
   "id": "960f2ffe02339e2c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T05:32:37.725922Z",
     "start_time": "2025-10-09T03:55:00.863441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "messages = [HumanMessage(content=\"解释一下RocketMQ的使用场景\")]\n",
    "\n",
    "print('流式输出Start....')\n",
    "\n",
    "for chunk in chat_model.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)\n",
    "\n",
    "print('流式输出End。。。')"
   ],
   "id": "256b72da6ac5f386",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "流式输出Start....\n",
      "RocketMQ 是一款开"
     ]
    },
    {
     "ename": "RemoteProtocolError",
     "evalue": "peer closed connection without sending complete message body (incomplete chunked read)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRemoteProtocolError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\httpx\\_transports\\default.py:101\u001B[39m, in \u001B[36mmap_httpcore_exceptions\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    100\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m101\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[32m    102\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\httpx\\_transports\\default.py:127\u001B[39m, in \u001B[36mResponseStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    126\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[32m--> \u001B[39m\u001B[32m127\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpart\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_httpcore_stream\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    128\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpart\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:407\u001B[39m, in \u001B[36mPoolByteStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    406\u001B[39m \u001B[38;5;28mself\u001B[39m.close()\n\u001B[32m--> \u001B[39m\u001B[32m407\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m exc \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:403\u001B[39m, in \u001B[36mPoolByteStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    402\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m403\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpart\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_stream\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    404\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpart\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\httpcore\\_sync\\http11.py:342\u001B[39m, in \u001B[36mHTTP11ConnectionByteStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    341\u001B[39m     \u001B[38;5;28mself\u001B[39m.close()\n\u001B[32m--> \u001B[39m\u001B[32m342\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\httpcore\\_sync\\http11.py:334\u001B[39m, in \u001B[36mHTTP11ConnectionByteStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    333\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[33m\"\u001B[39m\u001B[33mreceive_response_body\u001B[39m\u001B[33m\"\u001B[39m, logger, \u001B[38;5;28mself\u001B[39m._request, kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m334\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_connection\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_receive_response_body\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    335\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\httpcore\\_sync\\http11.py:203\u001B[39m, in \u001B[36mHTTP11Connection._receive_response_body\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    202\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m203\u001B[39m     event = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_receive_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    204\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(event, h11.Data):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\httpcore\\_sync\\http11.py:213\u001B[39m, in \u001B[36mHTTP11Connection._receive_event\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    212\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m213\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmap_exceptions\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[43mh11\u001B[49m\u001B[43m.\u001B[49m\u001B[43mRemoteProtocolError\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mRemoteProtocolError\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    214\u001B[39m \u001B[43m        \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_h11_state\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnext_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\contextlib.py:158\u001B[39m, in \u001B[36m_GeneratorContextManager.__exit__\u001B[39m\u001B[34m(self, typ, value, traceback)\u001B[39m\n\u001B[32m    157\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m158\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgen\u001B[49m\u001B[43m.\u001B[49m\u001B[43mthrow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtyp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraceback\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    159\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m    160\u001B[39m     \u001B[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001B[39;00m\n\u001B[32m    161\u001B[39m     \u001B[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001B[39;00m\n\u001B[32m    162\u001B[39m     \u001B[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\httpcore\\_exceptions.py:14\u001B[39m, in \u001B[36mmap_exceptions\u001B[39m\u001B[34m(map)\u001B[39m\n\u001B[32m     13\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(exc, from_exc):\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m to_exc(exc) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mexc\u001B[39;00m\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[31mRemoteProtocolError\u001B[39m: peer closed connection without sending complete message body (incomplete chunked read)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mRemoteProtocolError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 20\u001B[39m\n\u001B[32m     16\u001B[39m messages = [HumanMessage(content=\u001B[33m\"\u001B[39m\u001B[33m解释一下RocketMQ的使用场景\u001B[39m\u001B[33m\"\u001B[39m)]\n\u001B[32m     18\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m'\u001B[39m\u001B[33m流式输出Start....\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m20\u001B[39m \u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchat_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     21\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mprint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcontent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflush\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m     23\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m'\u001B[39m\u001B[33m流式输出End。。。\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:522\u001B[39m, in \u001B[36mBaseChatModel.stream\u001B[39m\u001B[34m(self, input, config, stop, **kwargs)\u001B[39m\n\u001B[32m    520\u001B[39m input_messages = _normalize_messages(messages)\n\u001B[32m    521\u001B[39m run_id = \u001B[33m\"\u001B[39m\u001B[33m-\u001B[39m\u001B[33m\"\u001B[39m.join((_LC_ID_PREFIX, \u001B[38;5;28mstr\u001B[39m(run_manager.run_id)))\n\u001B[32m--> \u001B[39m\u001B[32m522\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_stream\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    523\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m.\u001B[49m\u001B[43mid\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m:\u001B[49m\n\u001B[32m    524\u001B[39m \u001B[43m        \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m.\u001B[49m\u001B[43mid\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_id\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:916\u001B[39m, in \u001B[36mBaseChatOpenAI._stream\u001B[39m\u001B[34m(self, messages, stop, run_manager, stream_usage, **kwargs)\u001B[39m\n\u001B[32m    914\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m context_manager \u001B[38;5;28;01mas\u001B[39;00m response:\n\u001B[32m    915\u001B[39m     is_first_chunk = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m916\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    917\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    918\u001B[39m \u001B[43m            \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmodel_dump\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\openai\\_streaming.py:46\u001B[39m, in \u001B[36mStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     45\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> Iterator[_T]:\n\u001B[32m---> \u001B[39m\u001B[32m46\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mitem\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_iterator\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     47\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mitem\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\openai\\_streaming.py:58\u001B[39m, in \u001B[36mStream.__stream__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     55\u001B[39m process_data = \u001B[38;5;28mself\u001B[39m._client._process_response_data\n\u001B[32m     56\u001B[39m iterator = \u001B[38;5;28mself\u001B[39m._iter_events()\n\u001B[32m---> \u001B[39m\u001B[32m58\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msse\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     59\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msse\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstartswith\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m[DONE]\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     60\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mbreak\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\openai\\_streaming.py:50\u001B[39m, in \u001B[36mStream._iter_events\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     49\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_iter_events\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> Iterator[ServerSentEvent]:\n\u001B[32m---> \u001B[39m\u001B[32m50\u001B[39m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m._decoder.iter_bytes(\u001B[38;5;28mself\u001B[39m.response.iter_bytes())\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\openai\\_streaming.py:280\u001B[39m, in \u001B[36mSSEDecoder.iter_bytes\u001B[39m\u001B[34m(self, iterator)\u001B[39m\n\u001B[32m    278\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34miter_bytes\u001B[39m(\u001B[38;5;28mself\u001B[39m, iterator: Iterator[\u001B[38;5;28mbytes\u001B[39m]) -> Iterator[ServerSentEvent]:\n\u001B[32m    279\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Given an iterator that yields raw binary data, iterate over it & yield every event encountered\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m280\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_iter_chunks\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    281\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Split before decoding so splitlines() only uses \\r and \\n\u001B[39;49;00m\n\u001B[32m    282\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mraw_line\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplitlines\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    283\u001B[39m \u001B[43m            \u001B[49m\u001B[43mline\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mraw_line\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mutf-8\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\openai\\_streaming.py:291\u001B[39m, in \u001B[36mSSEDecoder._iter_chunks\u001B[39m\u001B[34m(self, iterator)\u001B[39m\n\u001B[32m    289\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Given an iterator that yields raw binary data, iterate over it and yield individual SSE chunks\"\"\"\u001B[39;00m\n\u001B[32m    290\u001B[39m data = \u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m291\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    292\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mline\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplitlines\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeepends\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    293\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mline\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\httpx\\_models.py:897\u001B[39m, in \u001B[36mResponse.iter_bytes\u001B[39m\u001B[34m(self, chunk_size)\u001B[39m\n\u001B[32m    895\u001B[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001B[32m    896\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request=\u001B[38;5;28mself\u001B[39m._request):\n\u001B[32m--> \u001B[39m\u001B[32m897\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mraw_bytes\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43miter_raw\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    898\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdecoded\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_bytes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    899\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunker\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdecoded\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\httpx\\_models.py:951\u001B[39m, in \u001B[36mResponse.iter_raw\u001B[39m\u001B[34m(self, chunk_size)\u001B[39m\n\u001B[32m    948\u001B[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001B[32m    950\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request=\u001B[38;5;28mself\u001B[39m._request):\n\u001B[32m--> \u001B[39m\u001B[32m951\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mraw_stream_bytes\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    952\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_num_bytes_downloaded\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mraw_stream_bytes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    953\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunker\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_stream_bytes\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\httpx\\_client.py:153\u001B[39m, in \u001B[36mBoundSyncStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    152\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> typing.Iterator[\u001B[38;5;28mbytes\u001B[39m]:\n\u001B[32m--> \u001B[39m\u001B[32m153\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_stream\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    154\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\httpx\\_transports\\default.py:126\u001B[39m, in \u001B[36mResponseStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    125\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> typing.Iterator[\u001B[38;5;28mbytes\u001B[39m]:\n\u001B[32m--> \u001B[39m\u001B[32m126\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmap_httpcore_exceptions\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    127\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpart\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_httpcore_stream\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    128\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpart\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\contextlib.py:158\u001B[39m, in \u001B[36m_GeneratorContextManager.__exit__\u001B[39m\u001B[34m(self, typ, value, traceback)\u001B[39m\n\u001B[32m    156\u001B[39m     value = typ()\n\u001B[32m    157\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m158\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgen\u001B[49m\u001B[43m.\u001B[49m\u001B[43mthrow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtyp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraceback\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    159\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m    160\u001B[39m     \u001B[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001B[39;00m\n\u001B[32m    161\u001B[39m     \u001B[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001B[39;00m\n\u001B[32m    162\u001B[39m     \u001B[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001B[39;00m\n\u001B[32m    163\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m exc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m value\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pyth311\\Lib\\site-packages\\httpx\\_transports\\default.py:118\u001B[39m, in \u001B[36mmap_httpcore_exceptions\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    115\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[32m    117\u001B[39m message = \u001B[38;5;28mstr\u001B[39m(exc)\n\u001B[32m--> \u001B[39m\u001B[32m118\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m mapped_exc(message) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mexc\u001B[39;00m\n",
      "\u001B[31mRemoteProtocolError\u001B[39m: peer closed connection without sending complete message body (incomplete chunked read)"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 批量调用",
   "id": "d7d73f71ff51b518"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T06:37:37.681367Z",
     "start_time": "2025-10-09T06:37:32.195620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "message1 = [SystemMessage(content=\"你是一个乐于助人的小助手小智\"), HumanMessage(content=\"你叫什么名字\")]\n",
    "message2 = [SystemMessage(content=\"你是一个乐于助人的小助手小智\"), HumanMessage(content=\"解释一下什么是Spring AI？\")]\n",
    "message3 = [SystemMessage(content=\"你是一个乐于助人的小助手小智\"), HumanMessage(content=\"简要概述一下Spring AI 和 Langchain的区别？\")]\n",
    "\n",
    "messages = [message1, message2, message3]\n",
    "\n",
    "response = chat_model.batch(messages)\n",
    "\n",
    "print(response)"
   ],
   "id": "2ec51208b29549ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='我叫小智，很高兴能帮助你！有什么问题可以问我哦。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 25, 'total_tokens': 44, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_efad92c60b', 'id': 'chatcmpl-COeZIbFSWF3gpxL63KMglJUjuyV9R', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--101a21bf-1d68-4cd7-9cc3-646c60ed8074-0', usage_metadata={'input_tokens': 25, 'output_tokens': 19, 'total_tokens': 44, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Spring AI是一个基于Spring框架的项目，旨在为开发者提供构建人工智能（AI）应用程序的工具和基础设施。它利用Spring生态系统的成熟性和灵活性，使开发者能够更轻松地集成各种AI服务和技术。\\n\\nSpring AI的主要特点包括：\\n\\n1. **简化集成**：提供便捷的方式来集成机器学习模型和AI服务，减少了配置和开发的复杂性。\\n\\n2. **可扩展性**：利用Spring的模块化特性，允许开发者根据需求自由扩展和定制。\\n\\n3. **与Spring生态系统兼容**：能够与Spring Boot、Spring Data等其他Spring项目无缝集成，便于构建完整的应用程序。\\n\\n4. **支持多种AI技术**：提供对深度学习、自然语言处理、计算机视觉等多种AI相关技术的支持。\\n\\n5. **开发者友好**：注重提高开发者的生产力，提供高效的编程模型和丰富的文档。\\n\\n通过Spring AI，开发者能够快速构建、部署和管理AI驱动的应用程序，同时享受Spring框架带来的强大功能和灵活性。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 267, 'prompt_tokens': 29, 'total_tokens': 296, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_efad92c60b', 'id': 'chatcmpl-COeZIf3lLhpptXDqFLD9mWXI9ZYWx', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--02aa28ac-f78f-44c0-bad2-aaa9393396cf-0', usage_metadata={'input_tokens': 29, 'output_tokens': 267, 'total_tokens': 296, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Spring AI 和 Langchain 是两个用于构建 AI 应用程序的不同框架。它们各自有不同的侧重点和应用场景。\\n\\n### Spring AI\\n- **背景**: Spring AI 是 Spring Framework 的一部分，专注于将人工智能集成到 Java 应用程序中。\\n- **特点**:\\n  - **Java 生态**: 适合于 Java 开发者，利用 Spring 的特性来构建企业应用。\\n  - **集成能力**: 可以与其他 Spring 项目无缝集成，适用于需要企业级支持和功能的应用。\\n  - **组件化**: 提供了多种组件，帮助开发者快速构建和管理 AI 相关的服务。\\n\\n### Langchain\\n- **背景**: Langchain 是一个为链式处理（Chain of Thought）设计的框架，主要用于简化与大型语言模型（LLM）的交互。\\n- **特点**:\\n  - **语言模型整合**: 专注于构建与 LLM 的对话代理和任务链，可以处理复杂的 NLP 任务。\\n  - **链式结构**: 支持将多个处理步骤串联起来，灵活地组合不同的 AI 功能。\\n  - **高度灵活**: 适合于快速原型制作及探索新的 AI 交互模式。\\n\\n### 总结\\n- **技术栈**: Spring AI 主要面向 Java 开发，而 Langchain 更关注于使用 Python 与 LLM 交互。\\n- **应用场景**: Spring AI 更加适合构建企业级应用，Langchain 则更适合快速实现复杂的 NLP 工作流。\\n\\n根据具体的技术需求和应用场景，开发者可以选择合适的框架来实现 AI 功能。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 385, 'prompt_tokens': 35, 'total_tokens': 420, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_efad92c60b', 'id': 'chatcmpl-COeZICeVI6lpQHLKgl2rHTguhubcc', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--7b86c85e-0b00-4e81-9f06-ac7c6dfdd2ef-0', usage_metadata={'input_tokens': 35, 'output_tokens': 385, 'total_tokens': 420, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 同步调用和异步调用",
   "id": "c6cce9b050bfdc13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T06:55:23.973632Z",
     "start_time": "2025-10-09T06:55:13.965553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "def call_model():\n",
    "    print(\"Start...\")\n",
    "    time.sleep(5)\n",
    "    print(\"End...\")\n",
    "\n",
    "def perform_other_tasks():\n",
    "    for i in range(5):\n",
    "        print(f\"other tasks: {i + 1}\")\n",
    "        time.sleep(1)\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    call_model()\n",
    "    perform_other_tasks()\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    return f\"耗时：{total_time}S\"\n",
    "main_time = main()\n",
    "print(main_time)"
   ],
   "id": "68864f3777a6387b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start...\n",
      "End...\n",
      "other tasks: 1\n",
      "other tasks: 2\n",
      "other tasks: 3\n",
      "other tasks: 4\n",
      "other tasks: 5\n",
      "耗时：10.003296136856079S\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import time\n",
    "import asyncio"
   ],
   "id": "ac7be1bac5c3e0f6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
