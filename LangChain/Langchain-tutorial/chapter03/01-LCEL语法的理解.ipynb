{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 关于LCEL语法的使用\n",
    "\n",
    "在使用管道符之前"
   ],
   "id": "9616ec0edfe4493a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T16:23:55.747136Z",
     "start_time": "2025-10-10T16:23:54.740138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. 获取大模型\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "joke_query = \"请讲一个笑话\"\n",
    "\n",
    "# 定义解析器\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# PromptTemplate为示例\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"回答用户的查询\\n 满足的格式为：{format_instructions}\\n 问题是：{question}\\n\",\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# prompt = prompt_template.invoke(input={\"question\": joke_query})\n",
    "# response = chat_model.invoke(prompt)\n",
    "# print(response.content)"
   ],
   "id": "c7491c2cb111a26b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"joke\": \"为什么计算机很擅长唱歌？因为它们有很多的微调！\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "使用管道符之后",
   "id": "8b89b1a954774456"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T16:25:51.272468Z",
     "start_time": "2025-10-10T16:25:50.077442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = prompt_template | chat_model | parser\n",
    "json_result = chain.invoke(input={\"question\": joke_query})\n",
    "print(json_result)"
   ],
   "id": "d3a30c47ccc43150",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': '为什么海洋总是很平静？\\n因为它知道如何控制潮流！'}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fad3a8863ce3d286"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 使用举例",
   "id": "4fa4e6fd50681fc4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T16:41:10.127340Z",
     "start_time": "2025-10-10T16:41:07.859452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"请给我讲一个关于{topic}很好笑的笑话\"\n",
    ")\n",
    "\n",
    "prompt_value = prompt_template.invoke({\"topic\":\"鸡\"})\n",
    "print(f\"prompt_value是:{prompt_value}\")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "result = chat_model.invoke(prompt_value)\n",
    "out_put = parser.invoke(result)\n",
    "\n",
    "print(out_put)\n",
    "print(type(out_put))"
   ],
   "id": "f33eaa81101ccd9e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_value是:text='请给我讲一个关于鸡很好笑的笑话'\n",
      "当然可以！这是一个关于鸡的笑话：\n",
      "\n",
      "有一天，一只鸡走进了图书馆，走到柜台前对图书管理员说：“咕咕咕，我要一本书。”  \n",
      "图书管理员愣了一下，给了它一本书。  \n",
      "第二天，鸡又来了，还是说：“咕咕咕，我要一本书。”  \n",
      "图书管理员觉得有点奇怪，但还是又给了它一本书。  \n",
      "到了第三天，鸡又来了，这次它说：“咕咕咕，我要两本书！”  \n",
      "图书管理员更好奇了，就决定跟着鸡看看到底它在做什么。\n",
      "\n",
      "鸡拿着书一路走到池塘边，那里有一只青蛙。  \n",
      "鸡把书递给青蛙，青蛙翻了翻书，然后说道：“不，这个不行，这个也不行。”\n",
      "\n",
      "所以鸡每天都在借书，是为了给青蛙找书看啊！\n",
      "\n",
      "鸡的工作可真有趣，找书也让我们感到好笑！希望你喜欢这个笑话！\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T16:43:44.056294Z",
     "start_time": "2025-10-10T16:43:40.889119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = prompt_template | chat_model | parser\n",
    "out_put2 = chain.invoke({\"topic\":\"老虎\"})\n",
    "print(out_put2)\n",
    "print(type(out_put2))"
   ],
   "id": "979e2da3744ddd0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然可以！这是一个关于老虎的笑话：\n",
      "\n",
      "有一天，一只老虎走进了一个酒吧，走到吧台前对 bartender 说：“请给我一杯水。”\n",
      "\n",
      "bartender 愣了一下，问道：“老虎，你怎么会喝水呢？”\n",
      "\n",
      "老虎微微一笑，说：“因为我在追求‘饮水思源’的生活方式！”\n",
      "\n",
      "希望这个笑话能让你笑一笑！\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
