{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 关于LCEL语法的使用\n",
    "\n",
    "在使用管道符之前"
   ],
   "id": "9616ec0edfe4493a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T16:23:55.747136Z",
     "start_time": "2025-10-10T16:23:54.740138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. 获取大模型\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "joke_query = \"请讲一个笑话\"\n",
    "\n",
    "# 定义解析器\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# PromptTemplate为示例\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"回答用户的查询\\n 满足的格式为：{format_instructions}\\n 问题是：{question}\\n\",\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# prompt = prompt_template.invoke(input={\"question\": joke_query})\n",
    "# response = chat_model.invoke(prompt)\n",
    "# print(response.content)"
   ],
   "id": "c7491c2cb111a26b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"joke\": \"为什么计算机很擅长唱歌？因为它们有很多的微调！\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "使用管道符之后",
   "id": "8b89b1a954774456"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T16:25:51.272468Z",
     "start_time": "2025-10-10T16:25:50.077442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = prompt_template | chat_model | parser\n",
    "json_result = chain.invoke(input={\"question\": joke_query})\n",
    "print(json_result)"
   ],
   "id": "d3a30c47ccc43150",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': '为什么海洋总是很平静？\\n因为它知道如何控制潮流！'}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fad3a8863ce3d286"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 使用举例",
   "id": "4fa4e6fd50681fc4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T16:41:10.127340Z",
     "start_time": "2025-10-10T16:41:07.859452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"请给我讲一个关于{topic}很好笑的笑话\"\n",
    ")\n",
    "\n",
    "prompt_value = prompt_template.invoke({\"topic\":\"鸡\"})\n",
    "print(f\"prompt_value是:{prompt_value}\")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "result = chat_model.invoke(prompt_value)\n",
    "out_put = parser.invoke(result)\n",
    "\n",
    "print(out_put)\n",
    "print(type(out_put))"
   ],
   "id": "f33eaa81101ccd9e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_value是:text='请给我讲一个关于鸡很好笑的笑话'\n",
      "当然可以！这是一个关于鸡的笑话：\n",
      "\n",
      "有一天，一只鸡走进了图书馆，走到柜台前对图书管理员说：“咕咕咕，我要一本书。”  \n",
      "图书管理员愣了一下，给了它一本书。  \n",
      "第二天，鸡又来了，还是说：“咕咕咕，我要一本书。”  \n",
      "图书管理员觉得有点奇怪，但还是又给了它一本书。  \n",
      "到了第三天，鸡又来了，这次它说：“咕咕咕，我要两本书！”  \n",
      "图书管理员更好奇了，就决定跟着鸡看看到底它在做什么。\n",
      "\n",
      "鸡拿着书一路走到池塘边，那里有一只青蛙。  \n",
      "鸡把书递给青蛙，青蛙翻了翻书，然后说道：“不，这个不行，这个也不行。”\n",
      "\n",
      "所以鸡每天都在借书，是为了给青蛙找书看啊！\n",
      "\n",
      "鸡的工作可真有趣，找书也让我们感到好笑！希望你喜欢这个笑话！\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T16:43:44.056294Z",
     "start_time": "2025-10-10T16:43:40.889119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = prompt_template | chat_model | parser\n",
    "out_put2 = chain.invoke({\"topic\":\"老虎\"})\n",
    "print(out_put2)\n",
    "print(type(out_put2))"
   ],
   "id": "979e2da3744ddd0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然可以！这是一个关于老虎的笑话：\n",
      "\n",
      "有一天，一只老虎走进了一个酒吧，走到吧台前对 bartender 说：“请给我一杯水。”\n",
      "\n",
      "bartender 愣了一下，问道：“老虎，你怎么会喝水呢？”\n",
      "\n",
      "老虎微微一笑，说：“因为我在追求‘饮水思源’的生活方式！”\n",
      "\n",
      "希望这个笑话能让你笑一笑！\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 传统Chain的调用\n",
    "\n",
    "## LLMChain 的使用"
   ],
   "id": "b9f5db4533f6c175"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T01:17:18.506238Z",
     "start_time": "2025-10-13T01:17:08.218705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "template = \"桌子上有{number}个苹果，4个桃子，5本书，一共几种水果？\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# 使用 LLMChain\n",
    "\n",
    "chain_llm = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "result = chain_llm.invoke({\"number\": 4})\n",
    "\n",
    "print(result)"
   ],
   "id": "cdcbf2d33eddc12d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_38240\\3885983201.py:15: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain_llm = LLMChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'number': 4, 'text': '桌子上有4个苹果和4个桃子。我们只考虑水果的种类，而不是数量。苹果和桃子是两种不同的水果，因此总共有2种水果。'}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### verbose使用",
   "id": "cad0bde4d82b9746"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T01:33:35.284608Z",
     "start_time": "2025-10-13T01:33:33.383885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一位{area}领域经验十分丰富的高端技术人才\"),\n",
    "        (\"human\", \"给我讲一个{adjective}的笑话\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "llm_chain = LLMChain(llm=chat_model, prompt=chat_template, verbose=True);\n",
    "\n",
    "response = llm_chain.invoke({\"area\": \"互联网\", \"adjective\": \"上班的牛马\"})\n",
    "print(response)"
   ],
   "id": "284bb253970c8d66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mSystem: 你是一位互联网领域经验十分丰富的高端技术人才\n",
      "Human: 给我讲一个上班的牛马的笑话\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'area': '互联网', 'adjective': '上班的牛马', 'text': '当然可以！这里有一个关于上班的牛马的笑话：\\n\\n一天，一头牛和一匹马在农场上聊天。牛说：“你知道吗，我每天都得挤奶工作，感觉像是个牛马工厂的员工。”\\n\\n马笑着说：“那可比我强多了！我每天只需要在跑道上走一圈，生活多轻松啊！”\\n\\n牛摇摇头，叹了口气说：“是啊，可是你得知道，到了周末的时候，可是没有牛奶喝的！”\\n\\n马哈哈大笑：“那就对了，谁让你不懂得‘周末放松’的道理呢？” \\n\\n希望这个小笑话能让你开心！'}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## SimpleSequentialChain使用",
   "id": "d532908f47513089"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T02:12:50.570814Z",
     "start_time": "2025-10-13T02:12:47.615239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chains import LLMChain, SimpleSequentialChain, SequentialChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\", streaming=True)\n",
    "\n",
    "print('----------基础组件初始化----------')\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "print('\\n----------SimpleSequentialChain----------')\n",
    "prompt_title = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"给我一个关于技术主题'{topic}'的吸引人的中文博客标题\")\n",
    "])\n",
    "\n",
    "chain_title = LLMChain(llm=chat_model, prompt=prompt_title)\n",
    "\n",
    "prompt_tweet = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"为这篇推文题目写一篇推文，标题是：{title}\")\n",
    "])\n",
    "\n",
    "chain_tweet = LLMChain(llm=chat_model, prompt=prompt_tweet)\n",
    "\n",
    "simple_chain = SimpleSequentialChain(chains=[chain_title, chain_tweet], verbose=True)\n",
    "\n",
    "simple_result = simple_chain.invoke(\"人工智能在医院智能导诊的作用？\")\n",
    "\n",
    "print(simple_result)"
   ],
   "id": "66bb04007ce15de4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------基础组件初始化----------\n",
      "\n",
      "----------SimpleSequentialChain----------\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new SimpleSequentialChain chain...\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3m《智慧医疗新篇章：人工智能如何革新医院导诊体验》\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m《智慧医疗新篇章：人工智能如何革新医院导诊体验》\n",
      "\n",
      "在数字化浪潮的推动下，人工智能正以前所未有的速度重塑医院的导诊体验。通过智能导诊系统，患者能够快速获取个性化的就医指导，减少等待时间，提升便捷性。不仅如此，AI还可以分析患者症状，辅助医护人员做出更精准的诊断。\n",
      "\n",
      "从智能问诊机器人到虚拟健康助手，AI技术的应用正在改善患者体验，提高医院运营效率。未来，AI将成为医疗服务的得力助手，让每位患者都能享受到更科学、更人性化的保障。\n",
      "\n",
      "让我们共同期待，智慧医疗带来的无限可能！#智慧医疗 #人工智能 #医院导诊\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'input': '人工智能在医院智能导诊的作用？', 'output': '《智慧医疗新篇章：人工智能如何革新医院导诊体验》\\n\\n在数字化浪潮的推动下，人工智能正以前所未有的速度重塑医院的导诊体验。通过智能导诊系统，患者能够快速获取个性化的就医指导，减少等待时间，提升便捷性。不仅如此，AI还可以分析患者症状，辅助医护人员做出更精准的诊断。\\n\\n从智能问诊机器人到虚拟健康助手，AI技术的应用正在改善患者体验，提高医院运营效率。未来，AI将成为医疗服务的得力助手，让每位患者都能享受到更科学、更人性化的保障。\\n\\n让我们共同期待，智慧医疗带来的无限可能！#智慧医疗 #人工智能 #医院导诊'}\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## SequentialChain\n",
    "\n",
    "- 多变量支持：不同子链有独立的输入/输出\n",
    "- 灵活映射：显式定义 变量如何从一个链到下一个链\n",
    "- 复杂流程控制：支持分支、条件逻辑（input_variables和output_variables来配置输入输出）"
   ],
   "id": "3bdeedf17d44d866"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T08:06:45.459402Z",
     "start_time": "2025-10-13T08:06:37.610521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# A Chain\n",
    "schainA_template = ChatPromptTemplate([\n",
    "    (\"system\", \"你是一个精通各个领域知识的知名教授\"),\n",
    "    (\"human\", \"尽可能详细的解释一下：{knowledge},以及：{action}\")\n",
    "])\n",
    "schainA_chains = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=schainA_template,\n",
    "    verbose=True,\n",
    "    output_key=\"schainA_chains_key\"\n",
    ")\n",
    "\n",
    "schainB_template = ChatPromptTemplate([\n",
    "    (\"system\", \"你非常善于总结文本中的重要信息，并做出简短的总结\"),\n",
    "    (\"human\", \"这是一个提问十分完整的解释说明内容：{schainA_chains_key}\"),\n",
    "    (\"human\", \"请你根据上述说明，尽可能简短的输出重要结论，控制在100字左右\")\n",
    "])\n",
    "\n",
    "schainB_chains = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=schainB_template,\n",
    "    verbose=True,\n",
    "    output_key=\"schainB_chains_key\"\n",
    ")\n",
    "\n",
    "seq_chain = SequentialChain(\n",
    "    chains=[schainA_chains, schainB_chains],\n",
    "    input_variables=[\"knowledge\", \"action\"],\n",
    "    output_variables=[\"schainA_chains_key\", \"schainB_chains_key\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = seq_chain.invoke({\n",
    "    \"knowledge\": \"国足为什么踢得这么好？\",\n",
    "    \"action\": \"举一个韦世豪的例子\"\n",
    "})\n",
    "\n",
    "# print(response)\n",
    "\n",
    "# 输出schainA_chains_key\n",
    "print(\"schainA_chains_key输出：\" + response[\"schainA_chains_key\"])\n",
    "# schainB_chains_key\n",
    "print(\"schainB_chains_key输出\" + response[\"schainB_chains_key\"])"
   ],
   "id": "3a96baaa3a82eae6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SequentialChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mSystem: 你是一个精通各个领域知识的知名教授\n",
      "Human: 尽可能详细的解释一下：国足为什么踢得这么好？,以及：举一个韦世豪的例子\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mSystem: 你非常善于总结文本中的重要信息，并做出简短的总结\n",
      "Human: 这是一个提问十分完整的解释说明内容：国足在近年来的表现引发了广泛的讨论和分析，但实际上，国足的状态和表现并不能简单地用“踢得好”来形容。相反，近年来国足的表现常常让人失望，甚至遭到批评。以下是一些可能影响国足表现的因素，以及韦世豪作为个例的分析。\n",
      "\n",
      "### 国足表现不佳的原因\n",
      "\n",
      "1. **基础设施建设不足**：\n",
      "   中国足球的青训系统和基础设施相对不够完善。虽然近年来有越来越多的足球学校和青训基地，但整体水平仍然较低。\n",
      "\n",
      "2. **战术和技术的局限性**：\n",
      "   国足在战术布置和球员技术方面的水平相对薄弱。这导致在与其他国家的球队对抗时，战术应变不灵活，技术细节容易出现失误。\n",
      "\n",
      "3. **心理素质问题**：\n",
      "   国足在面对比赛压力时，尤其是在关键比赛中，往往缺乏应对压力的能力，导致在关键时刻出现失误。\n",
      "\n",
      "4. **国内联赛水平**：\n",
      "   中超联赛的水平虽然引进了一些外籍球员，但过分依赖外援也影响了本土球员的成长和发展。\n",
      "\n",
      "5. **管理和支持***：\n",
      "   国家对足球的重视程度有波动，管理层的更迭和政策的不稳定，有时会导致球队的长期发展受阻。\n",
      "\n",
      "### 韦世豪的个例分析\n",
      "\n",
      "韦世豪是一名年轻的攻击型球员，他拥有出色的个人技术和相对较强的速度。他在国家队的一些比赛中表现出了个人能力，但整体表现依然受到更大背景的影响。\n",
      "\n",
      "1. **个人技术**：韦世豪在个人突破、射门和传球方面具有较强的能力，这让他在比赛中能够制造威胁。\n",
      "\n",
      "2. **适应能力**：在与不同对手对抗时，韦世豪能够通过快速的调整来适应比赛节奏，这也是他相对较好的表现原因之一。\n",
      "\n",
      "3. **心理素质**：作为年轻球员，韦世豪在一些比赛中的表现可能会因心态问题而起伏，但有时候他也能够在关键时刻展现出果敢和冷静。\n",
      "\n",
      "4. **团队配合**：虽然韦世豪个人能力出色，但他在国家队中仍需要与其他队员进行更好的配合，以提高整体的竞争力。\n",
      "\n",
      "### 总结\n",
      "\n",
      "国足的表现受限于多方面的因素，无法一概而论。而韦世豪作为其中的代表性球员，虽然有个人才能和发展潜力，却也在整体环境中面临着许多挑战。要想提升国足的整体表现，不仅仅需要依靠个别球员的出色发挥，更需要整体足球体系、青训系统的改革和发展。\n",
      "Human: 请你根据上述说明，尽可能简短的输出重要结论，控制在100字左右\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "schainA_chains_key输出：国足在近年来的表现引发了广泛的讨论和分析，但实际上，国足的状态和表现并不能简单地用“踢得好”来形容。相反，近年来国足的表现常常让人失望，甚至遭到批评。以下是一些可能影响国足表现的因素，以及韦世豪作为个例的分析。\n",
      "\n",
      "### 国足表现不佳的原因\n",
      "\n",
      "1. **基础设施建设不足**：\n",
      "   中国足球的青训系统和基础设施相对不够完善。虽然近年来有越来越多的足球学校和青训基地，但整体水平仍然较低。\n",
      "\n",
      "2. **战术和技术的局限性**：\n",
      "   国足在战术布置和球员技术方面的水平相对薄弱。这导致在与其他国家的球队对抗时，战术应变不灵活，技术细节容易出现失误。\n",
      "\n",
      "3. **心理素质问题**：\n",
      "   国足在面对比赛压力时，尤其是在关键比赛中，往往缺乏应对压力的能力，导致在关键时刻出现失误。\n",
      "\n",
      "4. **国内联赛水平**：\n",
      "   中超联赛的水平虽然引进了一些外籍球员，但过分依赖外援也影响了本土球员的成长和发展。\n",
      "\n",
      "5. **管理和支持***：\n",
      "   国家对足球的重视程度有波动，管理层的更迭和政策的不稳定，有时会导致球队的长期发展受阻。\n",
      "\n",
      "### 韦世豪的个例分析\n",
      "\n",
      "韦世豪是一名年轻的攻击型球员，他拥有出色的个人技术和相对较强的速度。他在国家队的一些比赛中表现出了个人能力，但整体表现依然受到更大背景的影响。\n",
      "\n",
      "1. **个人技术**：韦世豪在个人突破、射门和传球方面具有较强的能力，这让他在比赛中能够制造威胁。\n",
      "\n",
      "2. **适应能力**：在与不同对手对抗时，韦世豪能够通过快速的调整来适应比赛节奏，这也是他相对较好的表现原因之一。\n",
      "\n",
      "3. **心理素质**：作为年轻球员，韦世豪在一些比赛中的表现可能会因心态问题而起伏，但有时候他也能够在关键时刻展现出果敢和冷静。\n",
      "\n",
      "4. **团队配合**：虽然韦世豪个人能力出色，但他在国家队中仍需要与其他队员进行更好的配合，以提高整体的竞争力。\n",
      "\n",
      "### 总结\n",
      "\n",
      "国足的表现受限于多方面的因素，无法一概而论。而韦世豪作为其中的代表性球员，虽然有个人才能和发展潜力，却也在整体环境中面临着许多挑战。要想提升国足的整体表现，不仅仅需要依靠个别球员的出色发挥，更需要整体足球体系、青训系统的改革和发展。\n",
      "schainB_chains_key输出国足表现不佳的原因包括基础设施不足、战术局限、心理素质差、国内联赛影响及管理不稳定。韦世豪虽具个人才能，但仍受整体环境限制。提升国足需改革整体足球体系和青训系统，而非单靠个别球员的发挥。\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T08:23:46.166549Z",
     "start_time": "2025-10-13T08:23:42.606106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate.from_template(template=\"请模拟:{product}的市场价格，直接返回一个合理的价格数字，不要包含任何其他文字或单位，只需要数字\"),\n",
    "    verbose=True,\n",
    "    output_key=\"price\"\n",
    ")\n",
    "\n",
    "promo_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate.from_template(template=\"为{product}（售价：{price}元）创作一篇50字以内的促销文案，要求突出产品重点\"),\n",
    "    verbose=True,\n",
    "    output_key=\"promo_text\"\n",
    ")\n",
    "\n",
    "sequential_chain = SequentialChain(\n",
    "    chains=[query_chain, promo_chain],\n",
    "    verbose=True,\n",
    "    input_variables=[\"product\"],\n",
    "    output_variables=[\"price\", \"promo_text\"]\n",
    ")\n",
    "\n",
    "result = sequential_chain.invoke({\"product\": \"IPhone 17 Pro Max 2TB\"})\n",
    "\n",
    "print(result)"
   ],
   "id": "63f5e63a8c8696ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SequentialChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m请模拟:IPhone 17 Pro Max 2TB的市场价格，直接返回一个合理的价格数字，不要包含任何其他文字或单位，只需要数字\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m为IPhone 17 Pro Max 2TB（售价：15999元）创作一篇50字以内的促销文案，要求突出产品重点\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'product': 'IPhone 17 Pro Max 2TB', 'price': '15999', 'promo_text': '尽享极致科技！iPhone 17 Pro Max 2TB，超大存储，拍摄无界限，性能无与伦比。引领潮流，尽在掌握！现售仅15999元，带你体验未来手机的无限可能！快来抢购！'}\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LLMMathChain",
   "id": "eac2952d92576958"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T08:44:09.853260Z",
     "start_time": "2025-10-13T08:44:07.520334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chains import LLMMathChain\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "# 创建大模型实例\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "llm_math = LLMMathChain.from_llm(llm)\n",
    "\n",
    "res = llm_math.invoke(\"100 * 100 + 2 - (199 / 9) 等于多少？\")\n",
    "\n",
    "print(res)"
   ],
   "id": "34d17f821c387b53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '100 * 100 + 2 - (199 / 9) 等于多少？', 'answer': 'Answer: 9979.888888888889'}\n"
     ]
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
