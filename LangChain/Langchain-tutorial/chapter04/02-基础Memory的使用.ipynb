{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-13T14:50:46.784030Z",
     "start_time": "2025-10-13T14:50:46.398146Z"
    }
   },
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 创建模型实例\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ChatMessageHistory的使用\n",
    "\n",
    "1. 记忆存储"
   ],
   "id": "4744ee3919f7089e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T14:27:53.773298Z",
     "start_time": "2025-10-13T14:27:53.763674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "# 实例化\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "# 添加相关的消息存储\n",
    "history.add_user_message(\"你好\")\n",
    "history.add_ai_message(\"很不高兴认识你\")\n",
    "\n",
    "# 打印存储的消息\n",
    "print(history.messages)"
   ],
   "id": "2ceb837761ae1f27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='你好', additional_kwargs={}, response_metadata={}), AIMessage(content='很不高兴认识你', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. 对接大模型",
   "id": "79016a3046f54e95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T14:41:19.699527Z",
     "start_time": "2025-10-13T14:41:15.009001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_user_message(\"你好\")\n",
    "history.add_ai_message(\"很不高兴认识你\")\n",
    "history.add_user_message(\"帮我计算一下：1 + 1 * 8 = ？\")\n",
    "\n",
    "response = llm.invoke(history.messages)\n",
    "\n",
    "print(response.content)"
   ],
   "id": "ee673f85b51221f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据运算的优先级，乘法要先于加法。所以计算过程是：\n",
      "\n",
      "1 + (1 * 8) = 1 + 8 = 9\n",
      "\n",
      "所以，1 + 1 * 8 = 9。\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ConversationBufferMemory（基础）\n",
    "\n",
    "1. 返回存储的字符串信息"
   ],
   "id": "cc69c7250fa9332e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T14:50:26.954056Z",
     "start_time": "2025-10-13T14:50:26.667739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# inputs对应的就是用户消息，outputs对应的就是AI消息\n",
    "memory.save_context(inputs={\"input\": \"你好\"}, outputs={\"output\": \"很不高兴认识你\"})\n",
    "memory.save_context(inputs={\"input\": \"请帮我计算一下8 * 8 - 1 = ？\"}, outputs={\"output\": \"63\"})\n",
    "\n",
    "# 返回的字典结构的Key = history\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "9bc70281f1c0e0c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: 你好\\nAI: 很不高兴认识你\\nHuman: 请帮我计算一下8 * 8 - 1 = ？\\nAI: 63'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/hh4nchrn1sdcx7xtqspm_2nc0000gn/T/ipykernel_87150/4171666384.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. 以消息列表的形式返回存储消息",
   "id": "f69779c1fb796a6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T14:55:23.422087Z",
     "start_time": "2025-10-13T14:55:23.418744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# inputs对应的就是用户消息，outputs对应的就是AI消息\n",
    "memory.save_context(inputs={\"input\": \"你好\"}, outputs={\"output\": \"很不高兴认识你\"})\n",
    "memory.save_context(inputs={\"input\": \"请帮我计算一下8 * 8 - 1 = ？\"}, outputs={\"output\": \"63\"})\n",
    "\n",
    "# 返回的字典结构的Key = history\n",
    "print(memory.load_memory_variables({}))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# 原始消息列表\n",
    "print(memory.chat_memory.messages)"
   ],
   "id": "d0d879c29ba678f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: 你好\\nAI: 很不高兴认识你\\nHuman: 请帮我计算一下8 * 8 - 1 = ？\\nAI: 63'}\n",
      "\n",
      "\n",
      "[HumanMessage(content='你好', additional_kwargs={}, response_metadata={}), AIMessage(content='很不高兴认识你', additional_kwargs={}, response_metadata={}), HumanMessage(content='请帮我计算一下8 * 8 - 1 = ？', additional_kwargs={}, response_metadata={}), AIMessage(content='63', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. 结合大模型，提示词模版的使用（PromptTemplate）",
   "id": "a8a7111fab197419"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T15:19:38.398093Z",
     "start_time": "2025-10-13T15:19:36.710053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template=\"\"\"\n",
    "    你可以和人类对话\n",
    "    当前对话历史：{history}\n",
    "    人类问题：{question}\n",
    "    回复：\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "# memory = ConversationBufferMemory(memory_key=\"chat_history\") #显式设置history的名称，修改之后使用chat_history代替history\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt, memory=memory)\n",
    "\n",
    "response = chain.invoke({\"question\": \"你好，我叫小红\"})\n",
    "\n",
    "print(response)"
   ],
   "id": "427e1363e5cdb963",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '你好，我叫小红', 'history': '', 'text': '你好，小红！很高兴和你聊天。你今天过得怎么样？'}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T15:20:12.589743Z",
     "start_time": "2025-10-13T15:20:07.497813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "response = chain.invoke({\"question\": \"你好，我是谁？\"})\n",
    "\n",
    "print(response)"
   ],
   "id": "994e09121814ca61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '你好，我是谁？', 'history': 'Human: 你好，我叫小红\\nAI: 你好，小红！很高兴和你聊天。你今天过得怎么样？', 'text': '你好，小红！你刚刚告诉我你叫小红。有什么我可以帮助你的吗？'}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4. 显式设置",
   "id": "3467a225abc9fa12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8c4442f3f71cf1d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "5. 使用ChatPromptTemplate和return_messages",
   "id": "3c584ca33f4e3b55"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T15:45:44.804296Z",
     "start_time": "2025-10-13T15:45:43.797751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 创建Prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个与人类对话的机器人\"),\n",
    "    MessagesPlaceholder(\"history\"),\n",
    "    (\"human\", \"问题：{question}\")\n",
    "])\n",
    "\n",
    "# 创建Memory\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# 创建LLMChain\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, memory=memory)\n",
    "\n",
    "res1 = llm_chain.invoke({\"question\": \"中国首都在哪里？\"})\n",
    "\n",
    "print(res1, end=\"\\n\\n\")"
   ],
   "id": "c79a380be131d2a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '中国首都在哪里？', 'history': [HumanMessage(content='中国首都在哪里？', additional_kwargs={}, response_metadata={}), AIMessage(content='中国的首都是北京。', additional_kwargs={}, response_metadata={})], 'text': '中国的首都是北京。'}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T15:46:26.670036Z",
     "start_time": "2025-10-13T15:46:25.413565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res2 = llm_chain.invoke({\"question\": \"我刚才问的什么问题？\"})\n",
    "print(res2)"
   ],
   "id": "edc55e7326a8b075",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '我刚才问的什么问题？', 'history': [HumanMessage(content='中国首都在哪里？', additional_kwargs={}, response_metadata={}), AIMessage(content='中国的首都是北京。', additional_kwargs={}, response_metadata={}), HumanMessage(content='我刚才问的什么问题？', additional_kwargs={}, response_metadata={}), AIMessage(content='你刚才问的问题是“中国首都在哪里？”', additional_kwargs={}, response_metadata={})], 'text': '你刚才问的问题是“中国首都在哪里？”'}\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
